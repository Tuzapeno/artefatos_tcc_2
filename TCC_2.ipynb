{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry8Af3cPYiJa"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hsP_dEPO41e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variable configuration"
      ],
      "metadata": {
        "id": "J6f_lTk8cA83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory Paths\n",
        "BASE_DIR = '/content/drive/MyDrive/DATASETS_EXP'\n",
        "\n",
        "# Primary Dataset Paths\n",
        "BASE_DATA_DIR = os.path.join(BASE_DIR, 'Data')\n",
        "MODEL_SAVE_DIR = os.path.join(BASE_DIR, 'Models')\n",
        "PASTE_IMAGES_DIR = os.path.join(BASE_DIR, 'Augments')\n",
        "\n",
        "DATASET_DIR = os.path.join(BASE_DATA_DIR, \"PKLot_small\")\n",
        "\n",
        "TRAIN_DIR = os.path.join(\"/content/PKLot_small\", 'Train')\n",
        "TEST_DIR = os.path.join(\"/content/PKLot_small\", 'Test')\n",
        "\n",
        "GENERALIZATION_DIR = os.path.join(\"/content/CNRPark-EXT\", 'Test')\n",
        "\n",
        "\n",
        "# Paths for Copy-Paste Augmentation Images\n",
        "TREE_DIRECTORY = os.path.join(PASTE_IMAGES_DIR, 'Tree')\n",
        "POLE_DIRECTORY = os.path.join(PASTE_IMAGES_DIR, 'LightPole')\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "VALIDATION_SPLIT = 0.15\n",
        "SEED = 123\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "JFaOIi2zb_R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declaration of functions"
      ],
      "metadata": {
        "id": "KBbIY-396op3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting"
      ],
      "metadata": {
        "id": "8Up6P51C5FFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_misclassified_images(model, dataset, class_names, num_images=5):\n",
        "    misclassified_images = []\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    for image_batch, label_batch in dataset:\n",
        "        if len(misclassified_images) >= num_images:\n",
        "            break\n",
        "\n",
        "        preds_prob = model.predict(image_batch, verbose=0)\n",
        "        preds_batch = (preds_prob > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "        labels_np = label_batch.numpy().astype(\"int32\").flatten()\n",
        "\n",
        "        mismatch_indices = np.where(preds_batch != labels_np)[0]\n",
        "\n",
        "        for i in mismatch_indices:\n",
        "            if len(misclassified_images) < num_images:\n",
        "                image = image_batch[i].numpy()\n",
        "\n",
        "                # MobileNetV3 preprocess_input scales to [-1, 1]\n",
        "                # Convert back to [0, 1] for display\n",
        "                if image.min() < 0:  # If values are in [-1, 1] range\n",
        "                    image = (image + 1.0) / 2.0\n",
        "                else:  # If values are in [0, 255] range\n",
        "                    image = image / 255.0\n",
        "\n",
        "                # Ensure values are within [0, 1] range\n",
        "                image = np.clip(image, 0, 1)\n",
        "\n",
        "                misclassified_images.append(image)\n",
        "                predicted_labels.append(preds_batch[i])\n",
        "                true_labels.append(labels_np[i])\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    if not misclassified_images:\n",
        "        print(\"No misclassified images were found.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(25, 10))\n",
        "    for i in range(len(misclassified_images)):\n",
        "        plt.subplot(1, len(misclassified_images), i + 1)\n",
        "\n",
        "        image_to_plot = misclassified_images[i]\n",
        "\n",
        "        plt.imshow(image_to_plot)\n",
        "        pred_name = class_names[predicted_labels[i]]\n",
        "        true_name = class_names[true_labels[i]]\n",
        "        plt.title(f\"Predicted: {pred_name}\\nActual: {true_name}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7Y3c5QUv5Erg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback configuration\n",
        "\n"
      ],
      "metadata": {
        "id": "-kJls6xnn20W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    min_delta=0.01,\n",
        ")\n",
        "\n",
        "lr_plateau = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "CALLBACK_LIST = [early_stopping, lr_plateau]"
      ],
      "metadata": {
        "id": "T0-MQpXkn7eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and Evaluation"
      ],
      "metadata": {
        "id": "LD9lZChd5QFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mobilenet_model(input_shape):\n",
        "    base_model = tf.keras.applications.MobileNetV3Small(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output_layer)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_dataset, general_dataset, class_names, num_missed_images=4):\n",
        "\n",
        "    datasets_to_evaluate = [\n",
        "        (test_dataset, \"PKLot (Test)\"),\n",
        "        (general_dataset, \"CNRPark-EXT (Generalization)\")\n",
        "    ]\n",
        "\n",
        "    for dataset, name in datasets_to_evaluate:\n",
        "        print(f\"\\n\\n{'='*25}\\n   EVALUATING ON: {name}\\n{'='*25}\")\n",
        "\n",
        "        print(f\"\\nGenerating predictions for {name}...\")\n",
        "        y_pred_prob = model.predict(dataset, verbose=1)\n",
        "\n",
        "        print(\"Extracting true labels...\")\n",
        "        y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
        "\n",
        "        # Convert probabilities to class predictions\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "        if y_pred.ndim > 1 and y_pred.shape[1] == 1:\n",
        "            y_pred = y_pred.flatten()\n",
        "\n",
        "        print(f\"\\nClassification Report ({name}):\")\n",
        "        print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "\n",
        "        print(f\"\\nConfusion Matrix ({name}):\")\n",
        "        print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "        print(f\"\\nDisplaying Misclassified Images ({name})\")\n",
        "        plot_misclassified_images(model, dataset, class_names, num_missed_images)\n",
        "\n",
        "\n",
        "def run_experiment(experiment_name, train_data_config, model_builder_fn,\n",
        "                   train_dir, test_dir, gen_dir,\n",
        "                   img_shape, img_size, batch_size, epochs, val_split, callback_list):\n",
        "\n",
        "    print(f\"\\n{'='*20} STARTING EXPERIMENT: {experiment_name.upper()} {'='*20}\")\n",
        "\n",
        "    print(\"\\nLoading Datasets\")\n",
        "    train_ds, val_ds, test_ds, general_ds, class_names = load_datasets(\n",
        "        train_dir, test_dir, gen_dir, img_size, batch_size, val_split\n",
        "    )\n",
        "\n",
        "    print(\"\\nConfiguring Data Pipelines\")\n",
        "    train_ds = configure_dataset(train_ds, **train_data_config)\n",
        "    val_ds = configure_dataset(val_ds)\n",
        "    test_ds = configure_dataset(test_ds)\n",
        "    general_ds = configure_dataset(general_ds)\n",
        "    print(f\"Training data configured with: {train_data_config}\")\n",
        "\n",
        "    model = model_builder_fn(img_shape)\n",
        "    print(\"\\nModel builded\")\n",
        "\n",
        "    print(f\"\\nStarting Training for {experiment_name}\")\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=callback_list\n",
        "    )\n",
        "\n",
        "    plot_training_history(history)\n",
        "\n",
        "    print(f\"\\nEvaluating model...\")\n",
        "    evaluate_model(model, test_ds, general_ds, class_names)\n",
        "\n",
        "    print(f\"\\n{'='*20} FINISHED EXPERIMENT: {experiment_name.upper()} {'='*20}\")\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "AA2jLUwh5SNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation"
      ],
      "metadata": {
        "id": "OSMs90ST5wqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _apply_paste(image_array, paste_images_list, flip_h=False, flip_v=False, rotate=False):\n",
        "    base_image = tf.keras.preprocessing.image.array_to_img(image_array)\n",
        "\n",
        "    if paste_images_list:\n",
        "        paste_obj_pil = paste_images_list[np.random.randint(0, len(paste_images_list))]\n",
        "\n",
        "        if flip_h:\n",
        "            paste_obj_pil = paste_obj_pil.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
        "        if flip_v:\n",
        "            paste_obj_pil = paste_obj_pil.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
        "        if rotate:\n",
        "            paste_obj_pil = paste_obj_pil.rotate(np.random.randint(-45, 45))\n",
        "\n",
        "        base_w, base_h = base_image.size\n",
        "        paste_w, paste_h = paste_obj_pil.size\n",
        "\n",
        "        offset_x = (base_w - paste_w) // 2\n",
        "        offset_y = (base_h - paste_h) // 2\n",
        "\n",
        "        base_image.paste(paste_obj_pil, (offset_x, offset_y), paste_obj_pil)\n",
        "\n",
        "    return tf.keras.preprocessing.image.img_to_array(base_image)\n",
        "\n",
        "\n",
        "def copy_paste_augmentation(image, label, tree_chance=0.1, lightpole_chance=0.03):\n",
        "\n",
        "    def rnd():\n",
        "        return np.random.choice([True, False])\n",
        "\n",
        "    def augment(image):\n",
        "        if np.random.rand() < tree_chance:\n",
        "            image = _apply_paste(image, TREE_IMAGES, flip_h=rnd())\n",
        "\n",
        "        if np.random.rand() < lightpole_chance:\n",
        "            image = _apply_paste(image, LIGHT_POLE_IMAGES, flip_h=rnd())\n",
        "\n",
        "        return image\n",
        "\n",
        "    aug_image, = tf.py_function(augment, [image], [tf.float32])\n",
        "    aug_image.set_shape(IMG_SHAPE)\n",
        "    return aug_image, label\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "7Te6uTjB5wfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rf8LM2tYn41"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UoL-PiFo5lJ"
      },
      "outputs": [],
      "source": [
        "def load_datasets(train_dir, test_dir, generalization_dir, img_size, batch_size, val_split):\n",
        "    train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        validation_split=val_split,\n",
        "        subset=\"training\",\n",
        "        seed=SEED,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        validation_split=val_split,\n",
        "        subset=\"validation\",\n",
        "        seed=SEED,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        seed=SEED,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    generalization_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        generalization_dir,\n",
        "        seed=SEED,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    class_names = train_dataset.class_names\n",
        "    print(f\"Class names found: {class_names}\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, generalization_dataset, class_names\n",
        "\n",
        "\n",
        "def configure_dataset(dataset, copy_paste=False, data_augment=False, tree_chance=0.1, lightpole_chance=0.03):\n",
        "    if copy_paste:\n",
        "        def augment_batch(images, labels):\n",
        "            aug_images = tf.map_fn(\n",
        "                lambda img: copy_paste_augmentation(img, None, tree_chance, lightpole_chance)[0],\n",
        "                images,\n",
        "                dtype=tf.float32\n",
        "            )\n",
        "            return aug_images, labels\n",
        "        dataset = dataset.map(augment_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if data_augment:\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "9LzCQJ8hCsmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip_file(zip_file_path, destination_path):\n",
        "    os.makedirs(destination_path, exist_ok=True)\n",
        "    print(f\"Extracting '{os.path.basename(zip_file_path)}' to '{destination_path}'...\")\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination_path)\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "def _load_images_from_dir(dir_path):\n",
        "    images = []\n",
        "    if not os.path.exists(dir_path):\n",
        "        print(f\"Warning: Directory not found at '{dir_path}'\")\n",
        "        return images\n",
        "\n",
        "    for filename in sorted(os.listdir(dir_path)):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            try:\n",
        "                img_path = os.path.join(dir_path, filename)\n",
        "                img = Image.open(img_path).convert(\"RGBA\")\n",
        "                images.append(img)\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load image {filename}: {e}\")\n",
        "\n",
        "    return images\n",
        "\n",
        "def load_augment_images(tree_dir, pole_dir):\n",
        "    tree_images = _load_images_from_dir(tree_dir)\n",
        "    print(f\"Loaded {len(tree_images)} images from '{tree_dir}'.\")\n",
        "\n",
        "    light_pole_images = _load_images_from_dir(pole_dir)\n",
        "    print(f\"Loaded {len(light_pole_images)} images from '{pole_dir}'.\")\n",
        "\n",
        "    return tree_images, light_pole_images\n",
        "\n",
        "# Load Augmentation Images\n",
        "try:\n",
        "    TREE_IMAGES, LIGHT_POLE_IMAGES = load_augment_images(TREE_DIRECTORY, POLE_DIRECTORY)\n",
        "except FileNotFoundError:\n",
        "    print(\"Warning: Augmentation directories not found. Skipping image loading.\")"
      ],
      "metadata": {
        "id": "JbFq_gR95npU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdqVru-oYS5I"
      },
      "source": [
        "# Unzip CNRPark-EXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYH-6bgr8qKo"
      },
      "outputs": [],
      "source": [
        "unzip_file(os.path.join(BASE_DATA_DIR, 'CNRPark-EXT.zip'), '/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip PKLot"
      ],
      "metadata": {
        "id": "Vv427Pz5C2Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_file(os.path.join(BASE_DATA_DIR, 'PKLot_small.zip'), '/content/')"
      ],
      "metadata": {
        "id": "5lZY6jz4C9jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti_XxEpvh3N2"
      },
      "source": [
        "# Test Copy Paste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC1umMURSvyK"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Find the first class sub-directory in the training path (e.g., 'Occupied')\n",
        "    class_folders = [d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]\n",
        "    if not class_folders:\n",
        "        raise FileNotFoundError(f\"No class subdirectories found in '{TRAIN_DIR}'\")\n",
        "\n",
        "    first_class_folder = class_folders[1]\n",
        "    class_path = os.path.join(TRAIN_DIR, first_class_folder)\n",
        "\n",
        "    # Find the first image in that sub-directory\n",
        "    image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    if not image_files:\n",
        "        raise FileNotFoundError(f\"No images found in '{class_path}'\")\n",
        "\n",
        "    sample_image_path = os.path.join(class_path, image_files[0])\n",
        "    print(f\"Using sample image: {sample_image_path}\")\n",
        "\n",
        "    # Load the original image using PIL and convert to a NumPy array\n",
        "    original_image = Image.open(sample_image_path)\n",
        "    original_image_array = np.array(original_image)\n",
        "\n",
        "    # Apply each copy-paste augmentation individually to the original image\n",
        "    tree_pasted_image = _apply_paste(original_image_array, TREE_IMAGES, flip_h=True)\n",
        "    pole_pasted_image = _apply_paste(original_image_array, LIGHT_POLE_IMAGES, flip_h=True)\n",
        "\n",
        "    # Convert the processed images back to a displayable format (uint8)\n",
        "    images_to_plot = {\n",
        "        \"Original Image\": original_image_array,\n",
        "        \"With Tree\": np.clip(tree_pasted_image, 0, 255).astype(np.uint8),\n",
        "        \"With Light Pole\": np.clip(pole_pasted_image, 0, 255).astype(np.uint8),\n",
        "    }\n",
        "\n",
        "    # Plot all four images for comparison\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i, (title, img) in enumerate(images_to_plot.items()):\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except (FileNotFoundError, IndexError) as e:\n",
        "    print(f\"Error finding a sample image: {e}\")\n",
        "except NameError as e:\n",
        "    print(f\"An error occurred, check if augmentation images (TREE_IMAGES, etc.) were loaded correctly: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FEso084QtPG"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "-X8VieGOA2K2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_configuration = {\n",
        "    'data_augment': False,\n",
        "    'copy_paste': False,\n",
        "    'tree_chance': 0,\n",
        "    'lightpole_chance': 0,\n",
        "}\n",
        "\n",
        "copypaste_configuration = {\n",
        "    'data_augment': False,\n",
        "    'copy_paste': True,\n",
        "    'tree_chance': 0.1,\n",
        "    'lightpole_chance': 0.03,\n",
        "}"
      ],
      "metadata": {
        "id": "jsidvQJgFYXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = run_experiment(\n",
        "        \"pk_copypaste\",\n",
        "        copypaste_configuration,\n",
        "        build_mobilenet_model,\n",
        "        TRAIN_DIR,\n",
        "        TEST_DIR,\n",
        "        GENERALIZATION_DIR,\n",
        "        IMG_SHAPE,\n",
        "        IMG_SIZE,\n",
        "        BATCH_SIZE,\n",
        "        EPOCHS,\n",
        "        VALIDATION_SPLIT,\n",
        "        CALLBACK_LIST\n",
        ")"
      ],
      "metadata": {
        "id": "oG5099y6_Frm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_mobilenet_model(IMG_SHAPE)"
      ],
      "metadata": {
        "id": "UonysK87FfpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6ndyQTiZroN"
      },
      "source": [
        "## Save weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAyBCM-p1IU0"
      },
      "outputs": [],
      "source": [
        "# model_name = \"pk_copypaste\"\n",
        "# weights_filepath = os.path.join(MODEL_SAVE_DIR, f'{model_name}.weights.h5')\n",
        "# os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "# model.save_weights(weights_filepath)\n",
        "# print(f\"Weights saved at: {weights_filepath}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HyqMuNiZyPm"
      },
      "source": [
        "## Load weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL7hQO8M2t2j"
      },
      "outputs": [],
      "source": [
        "model_name = \"pk_copypaste\"\n",
        "weights_filepath = os.path.join(MODEL_SAVE_DIR, f'{model_name}.weights.h5')\n",
        "print(f\"Loading weights from: {weights_filepath}...\")\n",
        "model.load_weights(weights_filepath)\n",
        "print(f\"{model_name} loaded into the new model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests"
      ],
      "metadata": {
        "id": "43IxOewsC2He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = \"/content/drive/MyDrive/DATASETS_EXP/Data/Tests\"\n",
        "DATASET_NAME = \"PKLot\"\n",
        "TYPE = \"CopyPaste\""
      ],
      "metadata": {
        "id": "oGp241xAIW42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST_DIRS_PKLOT = [\"UFPR05\", \"UFPR04\", \"PUC\"]\n",
        "TEST_DIRS_PKLOT = [\"UFPR05\", \"UFPR04\", \"PUC\"]\n",
        "TEST_DIRS_CNR = [\"CAMERA1\", \"CAMERA2\", \"CAMERA3\", \"CAMERA4\", \"CAMERA5\", \"CAMERA6\", \"CAMERA7\", \"CAMERA8\", \"CAMERA9\", \"CNRPARK-TEST\"]"
      ],
      "metadata": {
        "id": "aiiFiepWDWjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = f\"/content/drive/MyDrive/DATASETS_EXP/Results/{DATASET_NAME}/{TYPE}\""
      ],
      "metadata": {
        "id": "TSRd3usbnFCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saving contents to directory:\", SAVE_DIR)\n",
        "\n",
        "for dir in TEST_DIRS_PKLOT:\n",
        "\n",
        "    unzip_file(os.path.join(TEST_DIR, f'{dir}.zip'), '/content/')\n",
        "\n",
        "    file_name = f\"{model_name}_{dir}.txt\"\n",
        "\n",
        "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        f\"/content/{dir}/Test\",\n",
        "        seed=SEED,\n",
        "        image_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        label_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    y_pred_prob = model.predict(test_dataset, verbose=1)\n",
        "\n",
        "    y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "    if y_pred.ndim > 1 and y_pred.shape[1] == 1:\n",
        "        y_pred = y_pred.flatten()\n",
        "\n",
        "    with open(f\"{SAVE_DIR}/{file_name}\", 'w') as f:\n",
        "        # Get the report string and confusion matrix array\n",
        "        report = classification_report(y_true, y_pred, target_names=test_dataset.class_names, digits=4)\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        # Print the report header and content to the file\n",
        "        print(\"--- Classification Report ---\", file=f)\n",
        "        print(report, file=f)\n",
        "\n",
        "        # Print a separator and the confusion matrix to the same file\n",
        "        print(\"\\n--- Confusion Matrix ---\", file=f)\n",
        "        print(cm, file=f)"
      ],
      "metadata": {
        "id": "UclOaEh2DzWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}